[{"title":"shell之获取docker容器中的cpu与内存使用率","url":"/2025/09/06/shell%E4%B9%8B%E8%8E%B7%E5%8F%96docker%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9A%84cpu%E4%B8%8E%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%E7%8E%87/","content":"背景：该项目迁移至新环境需求，将原先TSF集群（节点数：xxx）迁移到新环境中，jmeter 压测一个查询接口的数据。分别在旧环境与新环境的接口数据进行压测，对比监控CPU、内存利用率情况。目前旧环境容器无监控，故思路上使用脚本来获取监控数据，获取的数据用图标展示出来。底层的k8s比较老，暂未支持kubectl  top  容器。\n问题:为什么不进入容器中查看，top查看容器的资源使用量。这是因为我们在容器中运行 top 命令，虽然可以看到容器中每个进程的 CPU 使用率，但是 top 中”%Cpu(s)”那一行中显示的数值，并不是这个容器的 CPU 整体使用率，而是容器宿主机的 CPU 使用率。\n#!/bin/bashHOST_NAME=$(hostname -I | awk &#x27;&#123;print $2&#125;&#x27;)LOG_FILE=&quot;/var/log/docker_stats_20250719_$HOST_NAME.log&quot;DOCKER_NAME=$(docker ps |grep  &quot;tsf_1/element-server&quot; |awk &#x27;&#123;print $1&#125;&#x27;)INTERVAL=5 # 收集间隔（秒）# 创建日志文件并添加表头echo &quot;时间戳,容器ID,CPU使用率%,内存使用率%&quot; &gt; &quot;$LOG_FILE&quot;while true; do    # 获取当前时间戳    TIMESTAMP=$(date &#x27;+%H:%M:%S&#x27;)    # 使用 top 收集 CPU 使用率（提取 %Cpu(s): 后的数值）    CPU_MEM_USAGE=$(docker stats $DOCKER_NAME --no-stream --format &quot;&#123;&#123;.Container&#125;&#125;,\\t&#123;&#123;.CPUPerc&#125;&#125;,\\t\\t&#123;&#123;.MemPerc&#125;&#125;&quot;)    echo $CPU_MEM_USAGE    #top -bn1 | grep &#x27;%Cpu&#x27; | awk &#x27;&#123;print &quot;CPU使用率: &quot; 100 - $8 &quot;%&quot;&#125;&#x27;    echo &quot;$TIMESTAMP， $CPU_MEM_USAGE &quot;  &gt;&gt; &quot;$LOG_FILE&quot;    # 等待下一次收集    sleep $INTERVALdone\n\n最后制作出来的图标如下：\n\n关于得到的数据的疑问的记录\n从图标上可以得出有的CPU超100%了，原因是什么呢？正常来看这个CPU应该是多少的\n\n绝对资源消耗量\n\n307% = 3.07 个逻辑 CPU 核心满载#表示容器当前每秒消耗 3.07 核心秒的计算资#相当于： 3 个核心 100% 满载 + 第 4 个核心 7% 负载 或 4 个核心平均 76.75% 负载\n\n\ndocker stats 中查看 以下参数 docker 有关cpu配置的区别：\n\n[root@x.x.x.x ~]# docker inspect 1f77b1a2b98e |grep -i cpu            &quot;CpuShares&quot;: 4096, #cpu request的值            &quot;NanoCpus&quot;: 0,            &quot;CpuPeriod&quot;: 100000,            &quot;CpuQuota&quot;: 400000, #cpu limit的值            &quot;CpuRealtimePeriod&quot;: 0,            &quot;CpuRealtimeRuntime&quot;: 0,            &quot;CpusetCpus&quot;: &quot;9-12&quot;, #运行在哪个cpu上            &quot;CpusetMems&quot;: &quot;&quot;,            &quot;CpuCount&quot;: 0,            &quot;CpuPercent&quot;: 0,\n\n","categories":["工具"],"tags":["docker","shell"]},{"title":"容器化之细节问题处理篇01","url":"/2025/09/06/%E5%AE%B9%E5%99%A8%E5%8C%96%E4%B9%8B%E7%BB%86%E8%8A%82%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E7%AF%8701/","content":"问题现象：容器1，我们可以看到：\nPID 1： Java进程\n\n容器2，我们可以看到：\nPID 1: /sbin/tini -- ./entrypoint.shPID 6: Java进程\n\n关键区别在于：第二个容器的entrypoint.sh脚本可能是通过tini启动的。而第一个容器可能是直接以entrypoint.sh作为入口点，没有使用tini，所以在exec执行后Java进程替换了shell进程成为PID 1。\ndocker ps -a --no-trunc |grep xxx #查看docker 启动命令进行确认,使用docker run时指定了init程序为tini。\n\n这是因为在Dockerfile中可能使用了类似以下的指令：ENTRYPOINT [“&#x2F;sbin&#x2F;tini”, “–”, “.&#x2F;entrypoint.sh”]\ncat entrypoint.sh #!/bin/sh -eecho &quot;The application will start in $&#123;APP_SLEEP&#125;s...&quot; &amp;&amp; sleep $&#123;APP_SLEEP&#125;exec /usr/bin/java -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap $&#123;JAVA_OPTS&#125; \\     \t-Djava.security.egd=file:/dev/./urandom \\      -Dtsf.swagger.enabled=false \\     \t-jar /root/app/element-server2*.jar $&#123;RUN_ARGS&#125; &quot;$@&quot;\n\n\ntini 的作用\n\n1.tini 是一个轻量级的初始化系统，专门为容器设计\n\n1.可以确保它能正确接收 Docker 停止命令发送的信号\n\n2.它作为 PID 1 运行，负责管理子进程（这里是 entrypoint.sh）\n\n3.entrypoint.sh 脚本仍然使用 exec 启动 Java，但此时：\n  exec 替换的是 entrypoint.sh 进程（PID 6），而不是 PID 1\n  tini 保持为 PID 1，Java 进程作为其子进程运行\n\n\n两种方式的比较\n\n\n特性\n直接 exec (无 tini)\n使用 tini\n\n\n\nPID 1 进程\nJava 应用\ntini\n\n\n信号处理\n应用需自行处理\ntini 协助处理\n\n\n僵尸进程回收\n可能存在问题\n自动回收\n\n\n进程树结构\n更简单\n稍复杂但更健壮\n\n\n","categories":["容器化"],"tags":["docker"]},{"title":"容器化之细节问题处理篇02","url":"/2025/09/07/%E5%AE%B9%E5%99%A8%E5%8C%96%E4%B9%8B%E7%BB%86%E8%8A%82%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E7%AF%8702/","content":"背景：项目上需要将服务的日志都显示出来，对于有两类日志文件不能正常显示日志出来的。情况1：业务服务中未将服务日志打印在日志文件中，查看容器所在节点有查看到0.log 类似的日志，需要确认该日志是否就是服务的运行日志，目前针对该种日志产生的过程流程梳理\n容器的标准输出&#x2F;var&#x2F;log&#x2F;pods&#x2F;…&#x2F;0.log 文件的产生过程是：\nApp 输出 -&gt; stdout/stderr运行时捕获 -&gt; 容器运行时（Docker/containerd）将其写入自己的 JSON 日志文件中。kubelet 组织 -&gt; kubelet 创建清晰的目录结构，并通过符号链接指向容器运行时的原始日志文件。对外接口 -&gt; 这个路径成为了该容器日志在节点上的标准化、稳定的访问点。无论是系统管理员、日志采集代理（如 Filebeat、Fluentd），还是 kubectl logs 命令，最终都是通过读取这个路径下的文件来获取日志内容的。kubectl logs 命令的工作原理就是：apiserver -&gt; 对应节点的 kubelet -&gt; kubelet 读取 /var/log/pods/.../0.log 文件中的内容，解析 JSON 格式，只提取 log 字段的纯文本信息，然后流式传输回给请求者。\n\n关系与区别\n\n\n特性\n/var/log/pods/.../0.log (源文件:类比数据库原始表)\nkubectl logs (解析后的视图:类比执行SQL后的视图)\n\n\n\n内容\n原始、完整的数据\n解析后、筛选过的内容\n\n\n格式\nJSON格式，每行一条完整的JSON记录\n纯文本，只提取了JSON中的日志消息本身\n\n\n元数据\n包含丰富元数据，如完整的时间戳、流类型（stdout&#x2F;stderr）\n不包含JSON中的元数据，但可能会格式化输出时间戳（需加 --timestamps）\n\n\n访问方式\n直接登录到节点服务器查看文件\n通过Kubernetes API Server远程查询\n\n\n主要使用者\n系统、日志采集代理（如Fluentd, Filebeat）\n开发者、运维人员\n\n\n情况2：业务服务中日志打印显示是需要日志文件的挂载，目前挂载文件日志显示如下。mountPath: &#x2F;root&#x2F;app (服务启动jar在改目录) 则会挂载失败。原因:共享卷会把其他镜像内置的文件清空的。所以使用该种方式最好统一放在日志文件中，如下是该种情况的最佳实践\n        volumeMounts:        - mountPath: /root/app/log          name: test-log-l9ynkeyd-1...      volumes:      - emptyDir: &#123;&#125;        name: test-log-l9ynkeyd-1\n\n存储类型总结对比表格:\n\n\n存储类型\n概念理解\n生命周期\n\n\n\nemptyDir\n临时存储，会在节点创建空目录\n生命周期&#x3D;pod\n\n\nhostPath\n允许挂载宿主机文件到pod\n生命周期&#x3D;宿主机\n\n\nPVC&#x2F;PV\nKubernetes中持久存储的抽象，用户通过声明PVC请求存储资源，而PVC会绑定到满足其需求的PV\n持久存储\n\n\nStorageClass\n多个StorageClass，用户在创建PVC时指定StorageClass名称，以动态申请存储资源。\n持久存储\n\n\n详细场景说明\n","categories":["容器化"],"tags":["docker","存储"]},{"title":"我的第一篇博客","url":"/2025/09/06/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/","content":"欢迎来到我的博客！\n一下是开启我博客的开始之路\n一、创建于 Hexo + GitHub Pages 的搭建个人博客网站的详细教程\n二、更新博客的源码（Markdown文章、主题、配置等）通常存放在一个GitHub仓库中，而通过Hexo生成的静态网站文件则部署到GitHub Pages（通常是 username.github.io 仓库的特定分支，如 gh-pages 或 main）。\n\n📝 手动更新发布流程（本地完成）这种方式需要在计算机上配置好Hexo环境（Node.js, Git, Hexo等）。\n\n新建博文：使用命令创建新的Markdown文件。\nhexo new &quot;文章题目&quot;  # 或 hexo n &quot;文章题目&quot;\n\n\n\n这会在 source/_posts 目录下生成一个 文章题目.md 文件。\n\n编写&#x2F;更新内容：用文本编辑器（如VS Code）编辑生成的Markdown文件。\n\n生成静态文件：在Hexo站点根目录下执行命令，将Markdown转换为HTML等静态资源。\nhexo generate  # 或 hexo g\n\n\n\n如果需要先清除缓存和旧文件，可以使用：\nhexo clean &amp;&amp; hexo generate```:cite[1]\n\n\n\n本地预览（可选但推荐）：在部署前，最好先在本地启动服务器检查效果。\nhexo server  # 或 hexo s \n\n\n\n然后在浏览器中访问 http://localhost:4000 查看。\n\n部署到GitHub Pages：将生成好的静态文件（通常在 public 目录）推送至GitHub仓库的特定分支。\nhexo deploy  # 或 hexo d\n\n\n\n常用的便捷组合命令是：\nhexo clean &amp;&amp; hexo g &amp;&amp; hexo d为了能使用 `hexo deploy` 命令，您需要：在Hexo的**站点配置文件** (`_config.yml`) 中正确设置部署信息:    deploy:      type: git      repo: &lt;您的GitHub仓库SSH或HTTPS地址&gt;  # 例如 git@github.com:username/username.github.io.git      branch: &lt;部署分支，如gh-pages或main&gt; \n\n\n确保已安装 hexo-deployer-git 插件:cite[4]:cite[6]：npm install hexo-deployer-git --save\n\n\n推送源码（重要）：hexo deploy 通常只部署生成的静态文件。别忘了将您的博客源码（Markdown文章、主题、配置文件等）也推送到GitHub仓库的另一个分支（例如 source 或 hexo-source），以便备份和在多设备间同步。\n\n\n三、next 客制化页面3.1 字体设置\nfont:  #enable: false  enable: true  # Uri of fonts host, e.g. https://fonts.googleapis.com (Default).  host:  # Font options:  # `external: true` will load this font family from `host` above.  # `family: Times New Roman`. Without any quotes.  # `size: x.x`. Use `em` as unit. Default: 1 (16px)  # Global font settings used for all elements inside &lt;body&gt;.  global:    external: true    family: sans-serif    size: 0.725em  # Font settings for site title (.site-title).  title:    external: true    family:    size:  # Font settings for headlines (&lt;h1&gt; to &lt;h6&gt;).  headings:    external: true    family:    size:  # Font settings for posts (.post-body).  posts:    external: true    family:  # Font settings for &lt;code&gt; and code blocks.  #Roboto  codes:    external: true    family: Fira Code      size: .6em\n\n\n\n3.2 页面字体设置\ncat  themes/next/source/css/_variables/base.styl$font-size-base           = (hexo-config(&#x27;font.enable&#x27;) and hexo-config(&#x27;font.global.size&#x27;) is a &#x27;unit&#x27;) ? unit(hexo-config(&#x27;font.global.size&#x27;), em) : .8125em;//$font-size-base           = .8125em; #统一更改这个大小\n\n3.3 生效并部署\nhexo clean &amp;&amp; hexo g &amp;&amp; hexo d #清除缓存且浏览器也需无痕\n\n3.4 图片问题与设置\n#参数开启+插件安装+用hexo n 文档 去生成文档文件1.将_config.yml 文件中的post_asset_folder 选项设为 true 来打开2.npm install https://github.com/CodeFalling/hexo-asset-image --save\n\n图片设置不生效  标签与分类配置\n","categories":["杂篇"]},{"title":"记一次网卡修改及nmcli 使用","url":"/2025/09/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%BD%91%E5%8D%A1%E4%BF%AE%E6%94%B9%E5%8F%8Anmcli-%E4%BD%BF%E7%94%A8/","content":"因需要修改系统参数网卡队列，需要将其机器需要重启。目前发现集群一共100多台机器，重启其中一台master机器后，一直处于notReady状态。原因是因为改机器为双网卡，但是因为网卡名未固定。造成使用为固定的网卡未启动成功。\n解决思路：\n1. 查询100多台机器，/etc/udev/rules.d/70-persistent-net.rules  文件是否都含2条记录2.针对未含的节点操作，添加该条信息，网卡名不可修改，要与原先重启前一致。添加后如下：SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR&#123;address&#125;==&quot;fa:16:3e:98:70:9c&quot;, NAME=&quot;ens3&quot;SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR&#123;address&#125;==&quot;fa:16:3e:f5:e0:f1&quot;, NAME=&quot;ens10&quot; #更新的目标网卡名\n\n拓展：因加的网卡名变更为ens4，造成网卡一直up不起来。\n[root@tcs-10-25-83-48 network-scripts]# nmcli  device conn ens4错误：添加/激活新连接失败：Connection &#x27;ens4&#x27; is not available on device ens4 because device is strictly unmanaged\nnmcli处理过程：\nnmcli conn show  #查看设备连接情况nmcli conn show &quot;System ens4&quot; #查看网卡设置的详情nmcli conn reload #重启设备nmcli conn up ens4 #连接ens4设置nmcli device set &lt;网卡名称&gt; managed yes #激活网卡nmcli device #查看所有的设备nmcli device conn #将所有设备connnmcli device conn ens4 #网卡连接nmcli  networking #查看网络是由设置\n\n原因：\n[root@X-x.1-x.1-x.1-x.1 network-scripts]# cd /etc/NetworkManager/conf.d/[root@X-x.1-x.1-x.1-x.1 conf.d]# ls99-cloud-init.conf  99-container.conf[root@X-x.1-x.1-x.1-x.1 conf.d]# cat 99-cloud-init.conf # Created by cloud-init on instance boot automatically, do not edit.#[main]dns = none[root@X-x.1-x.1-x.1-x.1 conf.d]# cat 99-container.conf# avoid making container interface down[keyfile]unmanaged-devices=*,except:interface-name:ens10,except:interface-name:ens3 #99-container.conf，因容器平台部署完后，网卡名被获取到了并写入到类似文件中，故不建议修改网卡名称(即NAME=&quot;ens10&quot;)\n"}]